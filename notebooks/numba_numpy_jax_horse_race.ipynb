{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d74dc196",
   "metadata": {},
   "source": [
    "\n",
    "<a id='parallel'></a>\n",
    "<div id=\"qe-notebook-header\" align=\"right\" style=\"text-align:right;\">\n",
    "        <a href=\"https://quantecon.org/\" title=\"quantecon.org\">\n",
    "                <img style=\"width:250px;display:inline;\" width=\"250px\" src=\"https://assets.quantecon.org/img/qe-menubar-logo.svg\" alt=\"QuantEcon\">\n",
    "        </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e5617f",
   "metadata": {},
   "source": [
    "# Numba vs NumPy vs JAX\n",
    "\n",
    "**John Stachurski** Sept 2023\n",
    "\n",
    "[NumPy](https://numpy.org/) is a legacy Python library using pre-compiled code for array operations\n",
    "\n",
    "[Numba](https://numba.pydata.org/) is a modern JIT compiler built on LLVM\n",
    "\n",
    "[JAX](https://github.com/google/jax) is an \"open source\" Google project that combines \n",
    "\n",
    "* NumPy style array processing\n",
    "* a highly efficient JIT-compiler for array operations\n",
    "* automatic differentiation\n",
    "* the ability to specialize JIT-compiled code for CPUs / GPUs / TPUs\n",
    "\n",
    "In general\n",
    "\n",
    "* Numba is better for purely sequential single threaded tasks\n",
    "* JAX is better for parallelizable / array processing\n",
    "* NumPy is old-school but still convenient\n",
    "\n",
    "JAX almost always dominates NumPy in performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9648296",
   "metadata": {},
   "source": [
    "## How to run this lecture\n",
    "\n",
    "You can run this lecture on your laptop / desktop CPU if you install Anaconda Python + JAX for the CPU.  Uncomment what you need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a100bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install jax[CPU]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08539313",
   "metadata": {},
   "source": [
    "However, the real benefit of JAX comes with GPU access.\n",
    "\n",
    "The easiest way to get this is to \n",
    "\n",
    "- open this notebook on Google Colab\n",
    "- select \"Notebook settings\" and then add a GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c62d9f",
   "metadata": {},
   "source": [
    "We begin by importing some libraries that will be discussed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb86b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import randn\n",
    "import numba \n",
    "from numba import njit, vectorize, float64\n",
    "import matplotlib.pyplot as plt\n",
    "import jax\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15260fa",
   "metadata": {},
   "source": [
    "## Multivariate Optimization\n",
    "\n",
    "The problem is to maximize the function \n",
    "\n",
    "$$ f(x, y) = \\frac{\\cos \\left(x^2 + y^2 \\right)}{1 + x^2 + y^2} + 1$$\n",
    "\n",
    "using brute force --- searching over a grid of $(x, y)$ pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc72174a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, y):\n",
    "    return np.cos(x**2 + y**2) / (1 + x**2 + y**2) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf60bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d.axes3d import Axes3D\n",
    "from matplotlib import cm\n",
    "\n",
    "gridsize = 50\n",
    "gmin, gmax = -3, 3\n",
    "xgrid = np.linspace(gmin, gmax, gridsize)\n",
    "ygrid = xgrid\n",
    "x, y = np.meshgrid(xgrid, ygrid)\n",
    "\n",
    "# === plot value function === #\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(x,\n",
    "                y,\n",
    "                f(x, y),\n",
    "                rstride=2, cstride=2,\n",
    "                cmap=cm.jet,\n",
    "                alpha=0.4,\n",
    "                linewidth=0.05)\n",
    "\n",
    "ax.set_title(\"evaluate $f$ at all grid points\")\n",
    "ax.scatter(x, y, c='k', s=0.6)\n",
    "\n",
    "ax.scatter(x, y, f(x, y), c='k', s=0.6)\n",
    "\n",
    "ax.view_init(25, -57)\n",
    "ax.set_zlim(-0, 2.0)\n",
    "ax.set_xlim(gmin, gmax)\n",
    "ax.set_ylim(gmin, gmax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb017c54",
   "metadata": {},
   "source": [
    "For the grid size we set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630d1aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10_000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91d94fe",
   "metadata": {},
   "source": [
    "Let's try a few different methods to make it fast.\n",
    "\n",
    "### Vectorized Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ea2cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = np.linspace(-3, 3, num=n)\n",
    "\n",
    "x, y = np.meshgrid(grid, grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d71080",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_time = %timeit np.max(f(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb58d157",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"NumPy execution time = {numpy_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f58ed56",
   "metadata": {},
   "source": [
    "### JITTed code\n",
    "\n",
    "\n",
    "A jitted version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9870f91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit \n",
    "def compute_max():\n",
    "    m = -np.inf\n",
    "    for x in grid:\n",
    "        for y in grid:\n",
    "            z = np.cos(x**2 + y**2) / (1 + x**2 + y**2) + 1\n",
    "            if z > m:\n",
    "                m = z\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55764062",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748f867f",
   "metadata": {},
   "outputs": [],
   "source": [
    "numba_loops_time = %timeit out = compute_max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f03e2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Numba loops time = {numba_loops_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c6ba0b",
   "metadata": {},
   "source": [
    "Why is that faster than NumPy's highly optimized pre-compiled code???"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfa0f8d",
   "metadata": {},
   "source": [
    "### Vectorized Numba on the CPU\n",
    "\n",
    "\n",
    "We can use some tricks to add CPU-based parallelization via Numba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce868c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@vectorize('float64(float64, float64)', target='parallel')\n",
    "def f_par(x, y):\n",
    "    return np.cos(x**2 + y**2) / (1 + x**2 + y**2) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f48945",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = np.meshgrid(grid, grid)\n",
    "\n",
    "np.max(f_par(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3036304",
   "metadata": {},
   "outputs": [],
   "source": [
    "numba_vectorized_time = %timeit out = np.max(f_par(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecac1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Vectorized Numba time = {numba_vectorized_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27f2a1a",
   "metadata": {},
   "source": [
    "### JAX on the GPU\n",
    "\n",
    "Now let's try JAX.\n",
    "\n",
    "This code will work well if you have a GPU and JAX configured to use it.\n",
    "\n",
    "Let's see what we have available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f49b3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b703df",
   "metadata": {},
   "source": [
    "#### Replacing NumPy with JAX\n",
    "\n",
    "For this step we replace `np` with `jnp`, which is our alias for `jax.numpy`\n",
    "\n",
    "Warning --- you need a GPU with relatively large memory for this to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a46d6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, y):\n",
    "    return jnp.cos(x**2 + y**2) / (1 + x**2 + y**2) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d47aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = jnp.linspace(-3, 3, n)\n",
    "\n",
    "x, y = jnp.meshgrid(grid, grid)\n",
    "\n",
    "out = jnp.max(f(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da99272b",
   "metadata": {},
   "source": [
    "Here's our timing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfd96f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "jax_v1_time = %timeit out = jnp.max(f(x, y)).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30ed933",
   "metadata": {},
   "source": [
    "(Here `block_until_ready()` handles asynchronous execution.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ae0129",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"JAX V1 time = {jax_v1_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8b3aae",
   "metadata": {},
   "source": [
    "#### JIT Compiling the Function\n",
    "\n",
    "Let's JIT-compile the function and see if anything changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b60d777",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = jax.jit(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731a7e5f",
   "metadata": {},
   "source": [
    "With compile time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06099422",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "jnp.max(f(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be1c7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "jax_v2_time = %timeit out = jnp.max(f(x, y)).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924649a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"JAX V2 time = {jax_v2_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7fb374",
   "metadata": {},
   "source": [
    "Total speed gain over NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df00fe8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_time / jax_v2_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4a0f27",
   "metadata": {},
   "source": [
    "## Monte Carlo\n",
    "\n",
    "\n",
    "We wish to compute the mean of\n",
    "\n",
    "$$\n",
    "    S = (X_1 + X_2 + X_3)^p\n",
    "$$\n",
    "\n",
    "We assume that\n",
    "\n",
    "* $p$ is a positive number, which is known to us,\n",
    "* $X_i \\sim LN(\\mu_i, \\sigma_i)$ for $i=1,2,3$,\n",
    "* the values of $\\mu_i, \\sigma_i$ have all been estimated, and\n",
    "* the random variables $X_1$, $X_2$ and $X_3$ are independent.\n",
    "\n",
    "How should we compute the mean of $S$?\n",
    "\n",
    "To do this with pencil and paper is hard (unless, say, $p=1$).\n",
    "\n",
    "Instead we use Monte Carlo:\n",
    "\n",
    "1. Generate $n$ independent draws of $X_1$, $X_2$ and $X_3$ on a computer,\n",
    "1. Use these draws to generate $n$ independent draws of $S$, and\n",
    "1. Take the average value of these draws of $S$.\n",
    "\n",
    "By the law of large numbers, this average will be close to the true mean when\n",
    "$n$ is large.\n",
    "\n",
    "We use the following values for $p$ and each $\\mu_i$ and $\\sigma_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e194db33",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10_000_000\n",
    "p = 0.5\n",
    "μ_1, μ_2, μ_3 = 0.2, 0.8, 0.4\n",
    "σ_1, σ_2, σ_3 = 0.1, 0.05, 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786a8d5f",
   "metadata": {},
   "source": [
    "### A Vectorized Routine with NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b9bac1",
   "metadata": {},
   "source": [
    "Now we implement a vectorized routine using traditional NumPy array processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8522e64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_vectorized(n=10_000_000):\n",
    "    X_1 = np.exp(μ_1 + σ_1 * randn(n))\n",
    "    X_2 = np.exp(μ_2 + σ_2 * randn(n))\n",
    "    X_3 = np.exp(μ_3 + σ_3 * randn(n))\n",
    "    S = (X_1 + X_2 + X_3)**p\n",
    "    return(S.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfeadf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "compute_mean_vectorized()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52a0e9c",
   "metadata": {},
   "source": [
    "### Using Google JAX\n",
    "\n",
    "\n",
    "Let's try to shift this to the GPU and parallelize it effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a0b677",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8505cdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_jax(n=10_000_000):\n",
    "    key = jax.random.PRNGKey(1)\n",
    "    Z = jax.random.normal(key, (3, n))\n",
    "    X_1 = jnp.exp(μ_1 + σ_1 * Z[0,:])\n",
    "    X_2 = jnp.exp(μ_2 + σ_2 * Z[1,:])\n",
    "    X_3 = jnp.exp(μ_3 + σ_3 * Z[2,:])\n",
    "    S = (X_1 + X_2 + X_3)**p\n",
    "    return(S.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8828c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "compute_mean_jax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66c4b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_mean_jax_jitted = jax.jit(compute_mean_jax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0439f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "compute_mean_jax_jitted()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25c4f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "compute_mean_jax_jitted()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
